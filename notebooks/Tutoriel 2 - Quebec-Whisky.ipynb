{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import logging\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "df = pd.DataFrame.from_dict(data, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>categories</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;h2 class=\"entry-title\" itemprop=\"headline\"&gt;&lt;a...</td>\n",
       "      <td>&lt;span class=\"posted-on\"&gt;&lt;a href=\"http://quebec...</td>\n",
       "      <td>&lt;div class=\"entry-content\" itemprop=\"text\"&gt;\\n\\...</td>\n",
       "      <td>&lt;span class=\"cat-links\"&gt;&lt;span class=\"screen-re...</td>\n",
       "      <td>&lt;span class=\"tags-links\"&gt;&lt;span class=\"screen-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;h2 class=\"entry-title\" itemprop=\"headline\"&gt;&lt;a...</td>\n",
       "      <td>&lt;span class=\"posted-on\"&gt;&lt;a href=\"http://quebec...</td>\n",
       "      <td>&lt;div class=\"entry-content\" itemprop=\"text\"&gt;\\n\\...</td>\n",
       "      <td>&lt;span class=\"cat-links\"&gt;&lt;span class=\"screen-re...</td>\n",
       "      <td>&lt;span class=\"tags-links\"&gt;&lt;span class=\"screen-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;h2 class=\"entry-title\" itemprop=\"headline\"&gt;&lt;a...</td>\n",
       "      <td>&lt;span class=\"posted-on\"&gt;&lt;a href=\"http://quebec...</td>\n",
       "      <td>&lt;div class=\"entry-content\" itemprop=\"text\"&gt;\\n\\...</td>\n",
       "      <td>&lt;span class=\"cat-links\"&gt;&lt;span class=\"screen-re...</td>\n",
       "      <td>&lt;span class=\"tags-links\"&gt;&lt;span class=\"screen-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;h2 class=\"entry-title\" itemprop=\"headline\"&gt;&lt;a...</td>\n",
       "      <td>&lt;span class=\"posted-on\"&gt;&lt;a href=\"http://quebec...</td>\n",
       "      <td>&lt;div class=\"entry-content\" itemprop=\"text\"&gt;\\n\\...</td>\n",
       "      <td>&lt;span class=\"cat-links\"&gt;&lt;span class=\"screen-re...</td>\n",
       "      <td>&lt;span class=\"tags-links\"&gt;&lt;span class=\"screen-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;h2 class=\"entry-title\" itemprop=\"headline\"&gt;&lt;a...</td>\n",
       "      <td>&lt;span class=\"posted-on\"&gt;&lt;a href=\"http://quebec...</td>\n",
       "      <td>&lt;div class=\"entry-content\" itemprop=\"text\"&gt;\\n\\...</td>\n",
       "      <td>&lt;span class=\"cat-links\"&gt;&lt;span class=\"screen-re...</td>\n",
       "      <td>&lt;span class=\"tags-links\"&gt;&lt;span class=\"screen-r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  <h2 class=\"entry-title\" itemprop=\"headline\"><a...   \n",
       "1  <h2 class=\"entry-title\" itemprop=\"headline\"><a...   \n",
       "2  <h2 class=\"entry-title\" itemprop=\"headline\"><a...   \n",
       "3  <h2 class=\"entry-title\" itemprop=\"headline\"><a...   \n",
       "4  <h2 class=\"entry-title\" itemprop=\"headline\"><a...   \n",
       "\n",
       "                                                date  \\\n",
       "0  <span class=\"posted-on\"><a href=\"http://quebec...   \n",
       "1  <span class=\"posted-on\"><a href=\"http://quebec...   \n",
       "2  <span class=\"posted-on\"><a href=\"http://quebec...   \n",
       "3  <span class=\"posted-on\"><a href=\"http://quebec...   \n",
       "4  <span class=\"posted-on\"><a href=\"http://quebec...   \n",
       "\n",
       "                                                body  \\\n",
       "0  <div class=\"entry-content\" itemprop=\"text\">\\n\\...   \n",
       "1  <div class=\"entry-content\" itemprop=\"text\">\\n\\...   \n",
       "2  <div class=\"entry-content\" itemprop=\"text\">\\n\\...   \n",
       "3  <div class=\"entry-content\" itemprop=\"text\">\\n\\...   \n",
       "4  <div class=\"entry-content\" itemprop=\"text\">\\n\\...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  <span class=\"cat-links\"><span class=\"screen-re...   \n",
       "1  <span class=\"cat-links\"><span class=\"screen-re...   \n",
       "2  <span class=\"cat-links\"><span class=\"screen-re...   \n",
       "3  <span class=\"cat-links\"><span class=\"screen-re...   \n",
       "4  <span class=\"cat-links\"><span class=\"screen-re...   \n",
       "\n",
       "                                                tags  \n",
       "0  <span class=\"tags-links\"><span class=\"screen-r...  \n",
       "1  <span class=\"tags-links\"><span class=\"screen-r...  \n",
       "2  <span class=\"tags-links\"><span class=\"screen-r...  \n",
       "3  <span class=\"tags-links\"><span class=\"screen-r...  \n",
       "4  <span class=\"tags-links\"><span class=\"screen-r...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = ['André', 'Patrick', 'RV'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNan(x): return x != x\n",
    "\n",
    "def get_expert_rating(x): \n",
    "    if isNan(x): return x\n",
    "    \n",
    "    name_rating = (x[0].split(' '))\n",
    "    return np.nan if len(name_rating) < 2 else name_rating[1].split('%')[0]\n",
    "\n",
    "def remove_empty(x):\n",
    "    if isNan(x): return x\n",
    "    return x[1:] if x[0] == \"\\xa0\" else x\n",
    "\n",
    "def get_expert_name(x):\n",
    "    if isNan(x): return x\n",
    "    if len(x) == 0: return np.nan\n",
    "    \n",
    "    lenght = len(x[0])\n",
    "    return x[0].split(' ')[0] if lenght > 4 and lenght < 12 else np.nan\n",
    "\n",
    "def remove_unnecessary_text(text):\n",
    "    return np.nan if len(text) == 1 or len(text[0]) > 13 else text\n",
    "\n",
    "def get_cleaned_body(x):\n",
    "    body_list = x[0].split(' ')\n",
    "    \n",
    "    cleaned_body_list = []\n",
    "    \n",
    "    for i, y in enumerate(body_list):        \n",
    "        if y in experts:\n",
    "            cleaned_body_list.append(x)\n",
    "        else:\n",
    "            cleaned_body_list.append(x[1:])\n",
    "    \n",
    "    return remove_unnecessary_text(cleaned_body_list[0])\n",
    "\n",
    "def get_body(raw_html):\n",
    "    clean_text = BeautifulSoup(raw_html, \"lxml\").text.split('\\n')\n",
    "    return list(filter(None, clean_text))\n",
    "\n",
    "def get_degree(x):\n",
    "    degree = x[0].split('%')[0]\n",
    "    try:\n",
    "        degree = float(degree)\n",
    "    except ValueError:\n",
    "        degree = np.nan\n",
    "        \n",
    "    return degree\n",
    "\n",
    "def clean_title(x):\n",
    "    return BeautifulSoup(x, \"lxml\").a.text if x else np.nan\n",
    "\n",
    "def clean_tags(x):\n",
    "    return BeautifulSoup(x, \"lxml\").a.text if x else np.nan\n",
    "\n",
    "def clean_date(x):\n",
    "    return BeautifulSoup(x, \"lxml\").time.text\n",
    "\n",
    "def clean_categories(x):\n",
    "    x = cleanhtml(x)\n",
    "    return x[0].replace('Categories ', '')\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    clean_text = BeautifulSoup(raw_html, \"lxml\").text.split('\\n')\n",
    "    return list(filter(None, clean_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    df['categories'] = df['categories'].apply(lambda x: clean_categories(x))\n",
    "    df['date'] = df['date'].apply(lambda x: clean_date(x))\n",
    "    df['tags'] = df['tags'].apply(lambda x: clean_tags(x))\n",
    "    df['title'] = df['title'].apply(lambda x: clean_title(x))\n",
    "    df['body'] = df['body'].apply(lambda x: get_body(x))\n",
    "    df['alcohol_degree'] = df['body'].apply(lambda x: get_degree(x))\n",
    "    df['body'] = df['body'].apply(lambda x: x[1:])\n",
    "    df['body'] = df['body'].apply(lambda x: get_cleaned_body(x))\n",
    "    df['body'] = df['body'].apply(lambda i: remove_empty(i))\n",
    "\n",
    "    df['expert_name'] = df['body'].apply(lambda x: get_expert_name(x))\n",
    "    df['rating'] = df['body'].apply(lambda x: get_expert_rating(x))\n",
    "    df['body'] = df['body'].apply(lambda x: x[1:] if not isNan(x) else x)\n",
    "    df['description'] = df['body'].apply(lambda x: x[0] if not isNan(x) else x)\n",
    "    df['body'] = df['body'].apply(lambda x: x[1:] if not isNan(x) else x)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('body', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notna(df.categories)]\n",
    "df = df[pd.notna(df.description)]\n",
    "df = df[df['categories'].isin([\n",
    "    'Blends',\n",
    "    'Highlands',\n",
    "    'Islay',\n",
    "    'Speyside',\n",
    "    'Whiskey Américain',\n",
    "    'Whiskey Irlandais',\n",
    "    'Whisky Canadien',\n",
    "    'Whisky Japonais'\n",
    "])]\n",
    "cats, descs = zip(*df[['categories', 'description']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            tokenizer=lambda x: word_tokenize(x, language='french'),\n",
    "            lowercase=True,\n",
    "            # ngram_range=(1, 3),\n",
    "            stop_words=stopwords.words('french')\n",
    "        )),\n",
    "        ('clf', LogisticRegression(solver='liblinear')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(descs, cats, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(stop_words=['au', 'aux', 'avec', 'ce', 'ces',\n",
       "                                             'dans', 'de', 'des', 'du', 'elle',\n",
       "                                             'en', 'et', 'eux', 'il', 'ils',\n",
       "                                             'je', 'la', 'le', 'les', 'leur',\n",
       "                                             'lui', 'ma', 'mais', 'me', 'même',\n",
       "                                             'mes', 'moi', 'mon', 'ne', 'nos', ...],\n",
       "                                 tokenizer=<function <lambda> at 0x7fb07a1218b0>)),\n",
       "                ('clf', LogisticRegression(solver='liblinear'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "#     \"\"\"\n",
    "#     This function prints and plots the confusion matrix.\n",
    "#     Normalization can be applied by setting `normalize=True`.\n",
    "#     \"\"\"\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     plt.figure(figsize=(20, 20))\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=90)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     fmt = '.2f' if normalize else 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         plt.text(j, i, format(cm[i, j], fmt),\n",
    "#                  horizontalalignment=\"center\",\n",
    "#                  color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.show()\n",
    "    \n",
    "def evaluate_baseline(model, X_test, y_test):\n",
    "    logging.info(\"Predicting on test...\")\n",
    "    predicted = model.predict(X_test)\n",
    "    acc = np.mean(predicted == y_test)\n",
    "    logging.info(\"Accuracy on test: {}\".format(acc))\n",
    "    print(classification_report(y_test, predicted))\n",
    "#     plot_confusion_matrix(confusion_matrix(y_test, predicted), sorted(set(y_test)))\n",
    "\n",
    "\n",
    "    # Analyzing results here\n",
    "    clf = model.steps[1][1]\n",
    "    tf_idf_vectorizer = model.steps[0][1]\n",
    "    feature_names = tf_idf_vectorizer.get_feature_names()\n",
    "    for cls, coefs in zip(clf.classes_, clf.coef_):\n",
    "        print(\"=\"*20)\n",
    "        print(cls)\n",
    "        sorted_coefs = coefs.argsort()\n",
    "\n",
    "        topk_good_words = sorted_coefs[-10:][::-1]\n",
    "        good_words = {feature_names[i] for i in topk_good_words}\n",
    "        print(\"Top good words: {}\".format(good_words))\n",
    "\n",
    "        topk_bad_words = sorted_coefs[:10][::-1]\n",
    "        bad_words = {feature_names[i] for i in topk_bad_words}\n",
    "        print(\"Top bad words: {}\".format(bad_words))\n",
    "        print(\"=\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "           Blends       0.00      0.00      0.00        66\n",
      "        Highlands       0.67      0.02      0.04       102\n",
      "            Islay       0.72      0.90      0.80       146\n",
      "         Speyside       0.43      0.88      0.58       195\n",
      "Whiskey Américain       0.66      0.78      0.72       144\n",
      "Whiskey Irlandais       0.00      0.00      0.00        32\n",
      "  Whisky Canadien       0.95      0.24      0.38        76\n",
      "  Whisky Japonais       0.00      0.00      0.00        14\n",
      "\n",
      "         accuracy                           0.56       775\n",
      "        macro avg       0.43      0.35      0.31       775\n",
      "     weighted avg       0.55      0.56      0.47       775\n",
      "\n",
      "====================\n",
      "Blends\n",
      "Top good words: {'fumée', 'blended', 'rapidement', 'grains', 'céréales', 'complexe', 'grain', 'miel', 'équilibre', 'blend'}\n",
      "Top bad words: {'’', 'rouge', 'alcool', 'cerises', 'pomme', 'bourbon', 'rye', 'distillerie', 'bois', 'malt'}\n",
      "====================\n",
      "====================\n",
      "Highlands\n",
      "Top good words: {'rien', 'raisins', 'distillerie', 'glenmorangie', 'oranges', 'miel', 'single', 'orange', 'malt', 'chocolat'}\n",
      "Top bad words: {'rye', 'tourbe', '!', 'rouges', '.', 'si', ',', 'seigle', 'maïs', 'réglisse'}\n",
      "====================\n",
      "====================\n",
      "Islay\n",
      "Top good words: {'islay', 'fumée', 'sel', 'mer', 'tourbe', 'maritimes', 'tourbée', 'ardbeg', 'maritime', 'bowmore'}\n",
      "Top bad words: {'épicée', 'toffee', 'rye', 'sucre', '.', 'céréales', 'miel', 'chêne', 'épices', 'cannelle'}\n",
      "====================\n",
      "====================\n",
      "Speyside\n",
      "Top good words: {'toffee', 'glenrothes', 'âge', 'glenfiddich', 'macallan', 'herbe', '.', 'sherry', 'ans', 'chocolat'}\n",
      "Top bad words: {'fumée', 'sel', 'bourbon', 'mer', 'tourbe', 'rye', 'seigle', 'maïs', 'maritime', 'réglisse'}\n",
      "====================\n",
      "====================\n",
      "Whiskey Américain\n",
      "Top good words: {'cerises', 'rouge', 'bourbon', 'rye', 'sauvages', 'bourbons', 'maïs', 'cannelle', 'réglisse', 'brûlé'}\n",
      "Top bad words: {'poires', 'sel', 'raisins', 'tourbe', 'agrumes', 'miel', ',', 'notes', 'sherry', 'chocolat'}\n",
      "====================\n",
      "====================\n",
      "Whiskey Irlandais\n",
      "Top good words: {'poires', 'irlandais', 'céréales', 'whiskies', 'irish', 'grain', 'miel', 'whiskey', 'frais', 'vanille'}\n",
      "Top bad words: {'cerises', 'alcool', 'fumée', 'sel', 'bourbon', 'mer', 'rye', 'tourbe', 'chêne', '’'}\n",
      "====================\n",
      "====================\n",
      "Whisky Canadien\n",
      "Top good words: {'canadian', 'cassonade', 'rye', 'canadien', 'caramel', 'seigle', 'érable', 'sirop', 'cèdre', 'canadiens'}\n",
      "Top bad words: {'fumée', 'sel', 'mer', 'tourbe', ':', 'agrumes', 'miel', 'xérès', 'sherry', 'chocolat'}\n",
      "====================\n",
      "====================\n",
      "Whisky Japonais\n",
      "Top good words: {'japonais', 'passablement', 'whisky', 'retour', 'xérès', 'mousse', 'lait', 'jeune', 'noisettes', 'découvrir'}\n",
      "Top bad words: {'rye', 'distillerie', 'tourbe', '!', '.', ':', 'tropicaux', 'doux', ',', 'sherry'}\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngarneau/workspace/phd/accuracySharedTask/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ngarneau/workspace/phd/accuracySharedTask/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ngarneau/workspace/phd/accuracySharedTask/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_baseline(text_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " ',',\n",
       " '-même',\n",
       " '.',\n",
       " '..',\n",
       " '/',\n",
       " '//',\n",
       " '///',\n",
       " '/volume',\n",
       " '0-3/4',\n",
       " '1',\n",
       " '1.',\n",
       " '1.14',\n",
       " '1.50',\n",
       " '10',\n",
       " '10,000',\n",
       " '10-12',\n",
       " '10-15',\n",
       " '10.76',\n",
       " '10/2013',\n",
       " '100',\n",
       " '10000',\n",
       " '101',\n",
       " '105',\n",
       " '106',\n",
       " '10eme',\n",
       " '10ml',\n",
       " '10yo',\n",
       " '11',\n",
       " '11.99',\n",
       " '12',\n",
       " '12,15',\n",
       " '12.99',\n",
       " '120',\n",
       " '125',\n",
       " '125th',\n",
       " '129.65',\n",
       " '12yo',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '131',\n",
       " '1316e',\n",
       " '132',\n",
       " '135',\n",
       " '14',\n",
       " '1400',\n",
       " '14yo',\n",
       " '15',\n",
       " '15-20',\n",
       " '150',\n",
       " '150-200',\n",
       " '157',\n",
       " '15eme',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '1608…',\n",
       " '16yo',\n",
       " '17',\n",
       " '17/0121',\n",
       " '170',\n",
       " '18',\n",
       " '180',\n",
       " '1824',\n",
       " '1824.',\n",
       " '18yo',\n",
       " '1904',\n",
       " '1968',\n",
       " '1975/1983/1988',\n",
       " '1977',\n",
       " '1979',\n",
       " '1981',\n",
       " '1984',\n",
       " '1985',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1997.',\n",
       " '1998',\n",
       " '1ere',\n",
       " '1h30',\n",
       " '1st',\n",
       " '2',\n",
       " '2-3',\n",
       " '20',\n",
       " '20-25',\n",
       " '200',\n",
       " '2000',\n",
       " '2000.',\n",
       " '2001',\n",
       " '2003',\n",
       " '2004.',\n",
       " '2005',\n",
       " '2007',\n",
       " '2009',\n",
       " '2009.',\n",
       " '200eme',\n",
       " '200th',\n",
       " '2010',\n",
       " '2011',\n",
       " '2011.',\n",
       " '2013',\n",
       " '2014.',\n",
       " '2015',\n",
       " '2015.',\n",
       " '2016',\n",
       " '2017',\n",
       " '20yo',\n",
       " '21',\n",
       " '21yo',\n",
       " '22',\n",
       " '230',\n",
       " '24',\n",
       " '240',\n",
       " '246',\n",
       " '25',\n",
       " '250',\n",
       " '25yo',\n",
       " '26',\n",
       " '26yo',\n",
       " '27',\n",
       " '28',\n",
       " '2e',\n",
       " '2eme',\n",
       " '2×4',\n",
       " '2…',\n",
       " '3',\n",
       " '3-4',\n",
       " '3.197',\n",
       " '3.217',\n",
       " '3.219',\n",
       " '3.237.',\n",
       " '3.255',\n",
       " '3.3',\n",
       " '30',\n",
       " '300',\n",
       " '33',\n",
       " '331',\n",
       " '332',\n",
       " '35',\n",
       " '35000',\n",
       " '37',\n",
       " '375ml',\n",
       " '39',\n",
       " '390',\n",
       " '3ème',\n",
       " '4',\n",
       " '40',\n",
       " '400',\n",
       " '401',\n",
       " '40ppm',\n",
       " '42',\n",
       " '43',\n",
       " '45',\n",
       " '450',\n",
       " '46',\n",
       " '46.3',\n",
       " '468',\n",
       " '47',\n",
       " '47.7',\n",
       " '47.8',\n",
       " '48',\n",
       " '49',\n",
       " '4h00',\n",
       " '5',\n",
       " '5-10',\n",
       " '50',\n",
       " '50-55',\n",
       " '500',\n",
       " '500ml',\n",
       " '50eme',\n",
       " '50ml',\n",
       " '51.5',\n",
       " '53',\n",
       " '53.210',\n",
       " '53.5',\n",
       " '54',\n",
       " '55',\n",
       " '55.5',\n",
       " '55.7',\n",
       " '550',\n",
       " '56',\n",
       " '58',\n",
       " '5ml',\n",
       " '5yo',\n",
       " '6',\n",
       " '6-8',\n",
       " '60',\n",
       " '60-65',\n",
       " '600',\n",
       " '61',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '650',\n",
       " '7',\n",
       " '7-up',\n",
       " '70',\n",
       " '700',\n",
       " '700ml…près',\n",
       " '75',\n",
       " '750ml',\n",
       " '750ml…',\n",
       " '7up',\n",
       " '8',\n",
       " '80',\n",
       " '86',\n",
       " '88.',\n",
       " '9',\n",
       " '90',\n",
       " '91',\n",
       " '93',\n",
       " '95',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'a',\n",
       " 'a++',\n",
       " 'a-m-a-z-i-n-g',\n",
       " 'aaaaaah',\n",
       " 'aardvark…',\n",
       " 'abaisser',\n",
       " 'abaissé',\n",
       " 'abandonnes',\n",
       " 'abandonnez-vous',\n",
       " 'abasourdie',\n",
       " 'abattu',\n",
       " 'abattue',\n",
       " 'abeille',\n",
       " 'abeilles',\n",
       " 'aberfeldy',\n",
       " 'aberlour',\n",
       " 'abolition',\n",
       " 'abondamment',\n",
       " 'abondance',\n",
       " 'abondant',\n",
       " 'abondante',\n",
       " 'abondantes',\n",
       " 'abondants',\n",
       " 'abord',\n",
       " 'abordable',\n",
       " 'abordables',\n",
       " 'abords',\n",
       " 'abord…',\n",
       " 'aboutie',\n",
       " 'aboutira',\n",
       " 'abricot',\n",
       " 'abricots',\n",
       " 'abrupte',\n",
       " 'abruptement',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absente',\n",
       " 'absentes',\n",
       " 'absolument',\n",
       " 'abstraction',\n",
       " 'abunad',\n",
       " 'abunadh',\n",
       " 'abuser',\n",
       " 'abuserais',\n",
       " 'abv',\n",
       " 'acabit',\n",
       " 'acajou',\n",
       " 'accalmie',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accentuant',\n",
       " 'accentue',\n",
       " 'accentuent',\n",
       " 'accentuera',\n",
       " 'accentué',\n",
       " 'accentuée',\n",
       " 'accentués',\n",
       " 'accepte',\n",
       " 'accessible',\n",
       " 'accolades',\n",
       " 'accommodent',\n",
       " 'accompagnant',\n",
       " 'accompagne',\n",
       " 'accompagnement',\n",
       " 'accompagnent',\n",
       " 'accompagner',\n",
       " 'accompagné',\n",
       " 'accompagnée',\n",
       " 'accompagnées',\n",
       " 'accompagnés',\n",
       " 'accomplissement',\n",
       " 'accord',\n",
       " 'accorde',\n",
       " 'accordé',\n",
       " 'accoutumé',\n",
       " 'accoutumée',\n",
       " 'accrochant',\n",
       " 'accroche',\n",
       " 'accrochent',\n",
       " 'accrocher',\n",
       " 'accrocheront',\n",
       " 'accrocheur',\n",
       " 'accrochées',\n",
       " 'accrocs',\n",
       " 'accroit',\n",
       " 'accueillant',\n",
       " 'accueillir',\n",
       " 'accumule',\n",
       " 'accumulent',\n",
       " 'accuse',\n",
       " 'accusé',\n",
       " 'accès',\n",
       " 'accélérateur',\n",
       " 'acharne',\n",
       " 'achat',\n",
       " 'achats',\n",
       " 'achetable',\n",
       " 'acheter',\n",
       " 'achetez',\n",
       " 'acheté',\n",
       " 'achille',\n",
       " 'achète',\n",
       " 'achètent',\n",
       " 'achèterais',\n",
       " 'acide',\n",
       " 'acides',\n",
       " 'acidité',\n",
       " 'acidulé',\n",
       " 'acidulée',\n",
       " 'acidulés',\n",
       " 'acl',\n",
       " 'acolytes',\n",
       " 'acquisition',\n",
       " 'acquérir',\n",
       " 'acte',\n",
       " 'acteur',\n",
       " 'acteurs',\n",
       " 'action',\n",
       " 'actives',\n",
       " 'activités',\n",
       " 'actuels',\n",
       " 'acéré',\n",
       " 'acérée',\n",
       " 'acérées',\n",
       " 'acétone',\n",
       " 'acétones',\n",
       " 'adage',\n",
       " 'adaptée',\n",
       " 'addict',\n",
       " 'addition',\n",
       " 'additionnant',\n",
       " 'additionne',\n",
       " 'additionnel',\n",
       " 'additionnent',\n",
       " 'additionnera',\n",
       " 'additionneront',\n",
       " 'adeptes',\n",
       " 'adieu',\n",
       " 'admets',\n",
       " 'admettre',\n",
       " 'admirable',\n",
       " 'admirablement',\n",
       " 'admiratif',\n",
       " 'adn',\n",
       " 'ado',\n",
       " 'adolescent',\n",
       " 'adoptée',\n",
       " 'adorable',\n",
       " 'adorables',\n",
       " 'adore',\n",
       " 'adorer',\n",
       " 'adoreront',\n",
       " 'adore…',\n",
       " 'adoré',\n",
       " 'adorée',\n",
       " 'adouci',\n",
       " 'adoucie',\n",
       " 'adoucies',\n",
       " 'adoucir',\n",
       " 'adoucissant',\n",
       " 'adoucit',\n",
       " 'adresse',\n",
       " 'adressée',\n",
       " 'adrénaline',\n",
       " 'adulte',\n",
       " 'adultes',\n",
       " 'adversaire',\n",
       " 'advisory',\n",
       " 'adéquate',\n",
       " 'adéquatement',\n",
       " 'affaiblir',\n",
       " 'affaire',\n",
       " 'affaissée',\n",
       " 'affecte',\n",
       " 'affecter',\n",
       " 'affectera',\n",
       " 'affectionne',\n",
       " 'affectionnes',\n",
       " 'affichage',\n",
       " 'affichant',\n",
       " 'affiche',\n",
       " 'affichent',\n",
       " 'afficher',\n",
       " 'affichera',\n",
       " 'afficheront',\n",
       " 'affinage',\n",
       " 'affinant',\n",
       " 'affine',\n",
       " 'affiné',\n",
       " 'affirmait',\n",
       " 'affirmant',\n",
       " 'affirmation',\n",
       " 'affirme',\n",
       " 'affirment',\n",
       " 'affirmer',\n",
       " 'affirmera',\n",
       " 'affirmé',\n",
       " 'affirmée',\n",
       " 'affirmées',\n",
       " 'affirmés',\n",
       " 'afflige',\n",
       " 'affront',\n",
       " 'affrontement',\n",
       " 'affronter',\n",
       " 'affublant',\n",
       " 'affuble',\n",
       " 'affublent',\n",
       " 'affubler',\n",
       " 'affublé',\n",
       " 'affuté',\n",
       " 'affûte',\n",
       " 'affûté',\n",
       " 'afin',\n",
       " 'africaines',\n",
       " 'afréable',\n",
       " 'after',\n",
       " 'after-taste',\n",
       " 'aftertaste',\n",
       " 'agace',\n",
       " 'again',\n",
       " 'agave',\n",
       " 'agaye',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agence',\n",
       " 'agencement',\n",
       " 'agencements',\n",
       " 'agencent',\n",
       " 'agencé',\n",
       " 'agencées',\n",
       " 'agent',\n",
       " 'agençant',\n",
       " 'aggressivité',\n",
       " 'agit',\n",
       " 'agonie',\n",
       " 'agonisantes',\n",
       " 'agrablement',\n",
       " 'agrandir',\n",
       " 'agressif',\n",
       " 'agressifs',\n",
       " 'agressive',\n",
       " 'agressivement',\n",
       " 'agressives',\n",
       " 'agressivité',\n",
       " 'agricole',\n",
       " 'agricoles',\n",
       " 'agrippe',\n",
       " 'agrume',\n",
       " 'agrumes',\n",
       " 'agrumé',\n",
       " 'agrumés',\n",
       " 'agréable',\n",
       " 'agréablement',\n",
       " 'agréables',\n",
       " 'agréable…',\n",
       " 'agrément',\n",
       " 'agrémentant',\n",
       " 'agrémente',\n",
       " 'agrémenter',\n",
       " 'agrémenté',\n",
       " 'agrémentée',\n",
       " 'aguerris',\n",
       " 'aguichante',\n",
       " 'ah',\n",
       " 'aid',\n",
       " 'aidant',\n",
       " 'aide',\n",
       " 'aident',\n",
       " 'aider',\n",
       " 'aidera',\n",
       " 'aideront',\n",
       " 'aidé',\n",
       " 'aidée',\n",
       " 'aigre',\n",
       " 'aiguille',\n",
       " 'aiguilles',\n",
       " 'aiguisent',\n",
       " 'aiguisé',\n",
       " 'aiguisée',\n",
       " 'aiguisées',\n",
       " 'ailes',\n",
       " 'ailes…wow',\n",
       " 'ailleurs',\n",
       " 'ailleurs…',\n",
       " 'aime',\n",
       " 'aiment',\n",
       " 'aimer',\n",
       " 'aimerais',\n",
       " 'aimerait',\n",
       " 'aimeras',\n",
       " 'aimeront',\n",
       " 'aimes',\n",
       " 'aimez',\n",
       " 'aime…',\n",
       " 'aimiez',\n",
       " 'aimé',\n",
       " 'aimée',\n",
       " 'ainsi',\n",
       " 'air',\n",
       " 'aisément',\n",
       " 'ajout',\n",
       " 'ajoutant',\n",
       " 'ajoute',\n",
       " 'ajoutent',\n",
       " 'ajouter',\n",
       " 'ajouterais',\n",
       " 'ajouteront',\n",
       " 'ajoutes',\n",
       " 'ajoutez',\n",
       " 'ajouts',\n",
       " 'ajouté',\n",
       " 'ajoutée',\n",
       " 'ajusté',\n",
       " 'alambic',\n",
       " 'alambics',\n",
       " 'alan',\n",
       " 'alberta',\n",
       " 'album',\n",
       " 'alchimiste',\n",
       " 'alcoo',\n",
       " 'alcool',\n",
       " 'alcoolisé',\n",
       " 'alcoolisée',\n",
       " 'alcoolisées',\n",
       " 'alcoolisés',\n",
       " 'alcools',\n",
       " 'alcool…',\n",
       " 'ale',\n",
       " 'algue',\n",
       " 'algues',\n",
       " 'alimentation',\n",
       " 'alimenter',\n",
       " 'all',\n",
       " 'allait',\n",
       " 'allant',\n",
       " 'aller',\n",
       " 'allez',\n",
       " 'alliage',\n",
       " 'alliance',\n",
       " 'alliant',\n",
       " 'allie',\n",
       " 'allié',\n",
       " 'allo',\n",
       " 'allonge',\n",
       " 'allons',\n",
       " 'allt-a-bhaine',\n",
       " 'allumé',\n",
       " 'allure',\n",
       " 'allures',\n",
       " 'alléchant',\n",
       " 'alléchante',\n",
       " 'alléchantes',\n",
       " 'alors',\n",
       " 'alourdissant',\n",
       " 'alternative',\n",
       " 'altitude',\n",
       " 'altéré',\n",
       " 'aluminium',\n",
       " 'amadouent',\n",
       " 'amadoué',\n",
       " 'amadouée',\n",
       " 'amadouées',\n",
       " 'amalgame',\n",
       " 'amalgament',\n",
       " 'amalgamer',\n",
       " 'amalgamé',\n",
       " 'amalgamée',\n",
       " 'amande',\n",
       " 'amandes',\n",
       " 'amants',\n",
       " 'amateur',\n",
       " 'amateurs',\n",
       " 'amazing',\n",
       " 'ambassadeurs',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambigu',\n",
       " 'ambiguïté',\n",
       " 'ambigüe',\n",
       " 'ambigüité',\n",
       " 'ambitieuse',\n",
       " 'ambivalence',\n",
       " 'ambivalent',\n",
       " 'ambivalent…',\n",
       " 'ambler',\n",
       " 'ambuguité',\n",
       " 'amenant',\n",
       " 'amener',\n",
       " 'amer',\n",
       " 'american',\n",
       " 'amertume',\n",
       " 'ami',\n",
       " 'amiable',\n",
       " 'amical',\n",
       " 'amicale',\n",
       " 'amicalement',\n",
       " 'amidonnée',\n",
       " 'amie',\n",
       " 'amis',\n",
       " 'amitié',\n",
       " 'amour',\n",
       " 'amour-haine',\n",
       " 'amourache',\n",
       " 'amourachent',\n",
       " 'amoureuse',\n",
       " 'amoureusement',\n",
       " 'amoureuses',\n",
       " 'amoureux',\n",
       " 'ample',\n",
       " 'amplement',\n",
       " 'amples',\n",
       " 'ampleur',\n",
       " 'amplifiant',\n",
       " 'amplifie',\n",
       " 'amplifiera',\n",
       " 'amplifié',\n",
       " 'amplitude',\n",
       " 'ampute',\n",
       " 'amputer',\n",
       " 'amputera',\n",
       " 'amputé',\n",
       " 'amrut',\n",
       " 'amuse',\n",
       " 'amuser',\n",
       " 'amène',\n",
       " 'amènent',\n",
       " 'amère',\n",
       " 'amèrement',\n",
       " 'améliore',\n",
       " 'améliorent',\n",
       " 'amélioré',\n",
       " 'américain',\n",
       " 'américaine',\n",
       " 'américaines',\n",
       " 'américains',\n",
       " 'amérique',\n",
       " 'an',\n",
       " 'analyse',\n",
       " 'analyser',\n",
       " 'analysés',\n",
       " 'ananas',\n",
       " 'anasthésié',\n",
       " 'anchois',\n",
       " 'ancien',\n",
       " 'ancienne',\n",
       " 'anciennes',\n",
       " 'anciens',\n",
       " 'ancrent',\n",
       " 'ancrer',\n",
       " 'and',\n",
       " 'andrew',\n",
       " 'andré',\n",
       " 'anesthésiant',\n",
       " 'anesthésie',\n",
       " 'anesthésier',\n",
       " 'anesthésié',\n",
       " 'anesthésiée',\n",
       " 'anesthésiées',\n",
       " 'aneth',\n",
       " 'anges',\n",
       " 'anglais',\n",
       " 'anglaise',\n",
       " 'angle',\n",
       " 'angulaire',\n",
       " 'angélique',\n",
       " 'anicroches',\n",
       " 'animal',\n",
       " 'animale',\n",
       " 'animales',\n",
       " 'animé',\n",
       " 'anis',\n",
       " 'annihile',\n",
       " 'annihilera',\n",
       " 'annihilée',\n",
       " 'anniversaire',\n",
       " 'anniversaire…',\n",
       " 'anniversary',\n",
       " 'annoncaient',\n",
       " 'annonce',\n",
       " 'annonciateur',\n",
       " 'annoncé',\n",
       " 'annoncée',\n",
       " 'annoncées',\n",
       " 'annoncés',\n",
       " 'annonçait',\n",
       " 'annonçant',\n",
       " 'annuelle',\n",
       " 'année',\n",
       " 'années',\n",
       " 'années…',\n",
       " 'année…',\n",
       " 'anodin',\n",
       " 'anodine',\n",
       " 'anodines',\n",
       " 'anonyme',\n",
       " 'anonymous',\n",
       " 'ans',\n",
       " 'ansent',\n",
       " 'ans…',\n",
       " 'ans…et…',\n",
       " 'antan',\n",
       " 'anthony',\n",
       " 'anticipais',\n",
       " 'anticipation',\n",
       " 'anticipé',\n",
       " 'antipodes',\n",
       " 'antiseptique',\n",
       " 'antiseptiques',\n",
       " 'antérieures',\n",
       " 'anyway',\n",
       " 'an…',\n",
       " 'août',\n",
       " 'apaisant',\n",
       " 'apaisante',\n",
       " 'apaisantes',\n",
       " 'apaise',\n",
       " 'apaisée',\n",
       " 'apanage',\n",
       " 'apercevoir',\n",
       " 'aperçoit',\n",
       " 'aphasique',\n",
       " 'aplanies',\n",
       " 'aplanissent',\n",
       " 'aplomb',\n",
       " 'apogée',\n",
       " 'apogée…',\n",
       " 'apothéose',\n",
       " 'apparaissant',\n",
       " 'apparaisse',\n",
       " 'apparaissent',\n",
       " 'apparait',\n",
       " 'apparaitra',\n",
       " 'apparaitre',\n",
       " 'apparaitront',\n",
       " 'apparance',\n",
       " 'apparat',\n",
       " 'apparaît',\n",
       " 'apparence',\n",
       " 'apparent',\n",
       " 'apparentant',\n",
       " 'apparente',\n",
       " 'apparentent',\n",
       " 'apparentes',\n",
       " 'apparents',\n",
       " 'apparentées',\n",
       " 'apparition',\n",
       " 'appartenance',\n",
       " 'appartient',\n",
       " 'apparue',\n",
       " 'apparues',\n",
       " 'appel',\n",
       " 'appellation',\n",
       " 'appelle',\n",
       " 'appellent',\n",
       " 'appellerais',\n",
       " 'appelé',\n",
       " 'applaudiront',\n",
       " 'applique',\n",
       " 'appliquent',\n",
       " 'appliqueront',\n",
       " 'apport',\n",
       " 'apportaient',\n",
       " 'apportant',\n",
       " 'apporte',\n",
       " 'apportent',\n",
       " 'apporter',\n",
       " 'apportera',\n",
       " 'apporteront',\n",
       " 'apporté',\n",
       " 'apportée',\n",
       " 'apportées',\n",
       " 'apportés',\n",
       " 'apposée',\n",
       " 'apposés',\n",
       " 'apprendre',\n",
       " 'apprentissage',\n",
       " 'apprivoise',\n",
       " 'apprivoiser',\n",
       " 'apprivoisé',\n",
       " 'apprivoisée',\n",
       " 'approchable',\n",
       " 'approchables',\n",
       " 'approche',\n",
       " 'approcher',\n",
       " 'approprié',\n",
       " 'appropriée',\n",
       " 'appréciable',\n",
       " 'appréciant',\n",
       " 'apprécie',\n",
       " 'apprécier',\n",
       " 'apprécieront',\n",
       " 'apprécies',\n",
       " 'appréciez',\n",
       " 'apprécié',\n",
       " 'appréciée',\n",
       " 'apprété',\n",
       " 'apprêté',\n",
       " 'appui',\n",
       " 'appuie',\n",
       " 'appuient',\n",
       " 'appuies',\n",
       " 'appuyant',\n",
       " 'appuyé',\n",
       " 'appuyée',\n",
       " 'appuyées',\n",
       " 'appuyés',\n",
       " 'appétissant',\n",
       " 'appétissante',\n",
       " 'appétissantes',\n",
       " 'après',\n",
       " 'après-midi',\n",
       " 'après…',\n",
       " 'apte',\n",
       " 'aquafresh',\n",
       " 'aqueuse',\n",
       " 'aquilin',\n",
       " 'arachide',\n",
       " 'arachides',\n",
       " 'arbre',\n",
       " 'arbres',\n",
       " 'arbresde',\n",
       " 'arbustes',\n",
       " 'arc-en-ciel',\n",
       " 'archéologie',\n",
       " 'ardbeg',\n",
       " 'ardbegestre',\n",
       " 'ardbegs',\n",
       " 'ardbog',\n",
       " 'ardemment',\n",
       " 'ardeur',\n",
       " 'ardeurs',\n",
       " 'ardmore',\n",
       " 'argent',\n",
       " 'aristocratique',\n",
       " 'arme',\n",
       " 'armes',\n",
       " 'arnaque',\n",
       " 'aromatique',\n",
       " 'aromatiques',\n",
       " 'aromatisé',\n",
       " 'aromatisée',\n",
       " 'aromatisées',\n",
       " 'aromatisés',\n",
       " 'aromes',\n",
       " 'arondit',\n",
       " 'arraché',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrivee',\n",
       " 'arrivent',\n",
       " 'arriver',\n",
       " 'arrivera',\n",
       " 'arrives',\n",
       " 'arrivé',\n",
       " 'arrivée',\n",
       " 'arrière',\n",
       " 'arrière-goût',\n",
       " 'arrière-plan',\n",
       " 'arrière=plan',\n",
       " 'arrogant',\n",
       " 'arrondi',\n",
       " 'arrondie',\n",
       " 'arrondies',\n",
       " 'arrondir',\n",
       " 'arrondira',\n",
       " 'arrondis',\n",
       " 'arrondissant',\n",
       " 'arrondisse',\n",
       " 'arrondissent',\n",
       " 'arrondit',\n",
       " 'arrosée',\n",
       " 'arrête',\n",
       " 'arrêter',\n",
       " 'arrêtera',\n",
       " 'arrêtez',\n",
       " 'art',\n",
       " 'artifice',\n",
       " 'artifices',\n",
       " 'artificiel',\n",
       " 'artisanal',\n",
       " 'artisanale',\n",
       " 'artisanales',\n",
       " 'artisanaux',\n",
       " 'artisans',\n",
       " 'artiste',\n",
       " 'arôme',\n",
       " 'arômes',\n",
       " 'arômes…',\n",
       " 'asiatiques',\n",
       " 'asie',\n",
       " 'aspect',\n",
       " 'asphalte',\n",
       " 'asphalteuse',\n",
       " 'aspirent',\n",
       " 'asq',\n",
       " 'ass',\n",
       " 'assagit',\n",
       " 'assaille',\n",
       " 'assaisonner',\n",
       " 'assaisonné',\n",
       " 'assaisonnée',\n",
       " 'assaisonnées',\n",
       " 'assaisonnés',\n",
       " 'assaut',\n",
       " 'assemblage',\n",
       " 'assez',\n",
       " 'assez…',\n",
       " 'assimiler',\n",
       " 'assimilé',\n",
       " 'assis',\n",
       " 'assises',\n",
       " 'associe',\n",
       " 'associer',\n",
       " 'associes',\n",
       " 'associé',\n",
       " 'associée',\n",
       " 'associées',\n",
       " 'associés',\n",
       " 'assomme',\n",
       " 'assommé',\n",
       " 'assortie',\n",
       " 'assorties',\n",
       " 'assouplie',\n",
       " 'assume',\n",
       " 'assumer',\n",
       " 'assurance',\n",
       " 'assurer',\n",
       " 'assurée',\n",
       " 'assèche',\n",
       " 'assèchent',\n",
       " 'assèchera',\n",
       " 'assècheront',\n",
       " 'asséchant',\n",
       " 'asséchante',\n",
       " 'assécher',\n",
       " 'asséché',\n",
       " 'asséchée',\n",
       " 'astrigent',\n",
       " 'astrigente',\n",
       " 'astringeant',\n",
       " 'astringence',\n",
       " 'astringent',\n",
       " 'astringente',\n",
       " 'astringentes',\n",
       " 'astringents',\n",
       " 'atendre',\n",
       " 'atlantique',\n",
       " 'atlantiques',\n",
       " 'atours',\n",
       " 'atouts',\n",
       " 'atrophié',\n",
       " 'attachante',\n",
       " 'attache',\n",
       " 'attachent',\n",
       " 'attacher',\n",
       " 'attaque',\n",
       " 'attarde',\n",
       " 'attardent',\n",
       " 'attarder',\n",
       " 'atteignaient',\n",
       " 'atteignent',\n",
       " 'atteindre',\n",
       " 'atteint',\n",
       " 'atteinte',\n",
       " 'attend',\n",
       " 'attendais',\n",
       " 'attendais…',\n",
       " 'attendait',\n",
       " 'attendant',\n",
       " 'attendent',\n",
       " 'attendez',\n",
       " 'attendions',\n",
       " 'attendrait',\n",
       " 'attendre',\n",
       " 'attendre…',\n",
       " 'attendri',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer = text_clf.steps[0][1]\n",
    "tf_idf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = text_clf.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
